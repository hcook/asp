A Specialized, Embedded, Just-in-Time Specializer for Gaussian Mixture Model Algorithms

Henry Cook, Katya Gonina and Shoaib Kamil
{hcook, egonina, skamil}@eecs.berkeley.edu
3/9/2011


=== ABOUT ===

This readme is some intial documentation for a SEJIT specializer for GMM training and prediction built using the ASP framework.

The goal is for researchers programming in python to use the GMM class defined in em.py to write applications that use GMMs. Under the covers, em.py uses the tools included in the ASP framework to generate and compile efficient parallel versions of the algorithms called by the researcher's application.

This particular readme file is SPECIFIC TO THE SQUIDXX MACHINES AT ICSI. While the general information is applicable to other locations, all the variable bindings are ICSI-specific.


=== INSTALLING ===

While the eventual vision is that ASP will be a real Python library that is imported by any specializer that wants to use its facilities, noone has as yet done the work of making the configuration scripts, etc., that would actually install it. Since ASP is itself just python scripts, the current solution is to add new scripts and applications you create to the tests/ or examples/ subfolders of the ASP project. You'll have to set up some envirornment variables as discussed below.

1. Add the following lines to your ~/.bashrc file:

LD_LIBRARY_PATH=/u/drspeech/projects/parlab/build-64/boost/pool/lib:/usr/local64/lang/cuda-3.2/lib64;export LD_LIBRARY_PATH
PYTHONPATH=/u/drspeech/projects/parlab/build-64/python/lib/python2.6/site-packages;export PYTHONPATH
PATH=$PATH:/usr/local64/lang/cuda-3.2/bin; export PATH

2. Add the following lines to your ~/.aksetup-defaults.py file:

BOOST_PYTHON_LIBNAME=['boost_python']
BOOST_LIB_DIR = ['/u/drspeech/projects/parlab/build-64/boost/pool/lib']
BOOST_INC_DIR=['/u/drspeech/projects/parlab/build-64/boost/pool/include']
BOOST_BINDINGS_INC_DIR = ['/u/drspeech/projects/parlab/build-64/boost/pool/include/boost-numeric-bindings']

=== RUNNING ===

When you run any code that uses the specialized GMM class, you must have the top level asp folder in your $PYTHONPATH. You can either prefix the command with the variable or permanently modify it in .bashrc. You must also use the correct installation of Python:

~$ cd asp
asp$ PYTHONPATH=$PYTHONPATH:`pwd` /usr/local64/bin/python2.6.6 test/em_test.py

=== DIRECTORIES AND FILES ===

The top level ASP folder contains multiple *.py files, each of which defines a specializer. The specializer you will be using is the specializer for the E-M algorithm for Gaussian Mixture Models, which is contained in em.py.ram_space=None, device_id=0, means=None, covars=None, weights=None):oThe subdirectories of the asp project folder are:
* asp/ - The internal scripts that are shared by all specializers written using ASP
* templates/ - The internal source code templates used by ASP to generate code for various specializers
* tests/ - Scripts to test out the functionality of the various specializers
* examples/ - Applications written using one or more specializers

=== TESTS AND EXAMPLES ===

As a new user, you should look at two files:
* tests/em_test.py -  Provides validation of the correct performance of the different parallel versions of EM generated by the specializer
* examples/em_ahc_example.py - Provides a sample application that uses the GMM class from em.py to perform AHC

=== WRITING NEW PROGRAMS ===

Use the EM test and example to see how programs can use the GMM class, and look at the API below.

=== API FOR THE GMM CLASS ===

The API is based on the API for scikits.learn (http://scikit-learn.sourceforge.net/) but is not identical

class em.GMM( M, D, variant_param_space=None, device_id=0, means=None, covars=None, weights=None)
	Representation of a Gaussian mixture model probability distribution.
	Mandatory parameters:
		M, the number of components in the GMM
		D, the number of dimensions in the GMM
	Optional parameters:
		variant_param_space, a dictionary of tuning parameters for the the underlying code generator
		device_id, which GPU device to run algorithms on
		means, initial values for GMM mean vector
		covars, initial values for GMM covariance matrix
		weights, intial values for GMM weights vector

	Methods:
		train( input_data )
			Estimate model parameters with the expectation-maximization algorithm given some input data
			Parameters:
				input_data, must be a 2-d numpy.ndarray where every row is an event and every column a dimension
			Returns:
				gmm, the trained GMM

		eval( obs_data )
			Evaluate the model on data. Compute the log probability of obs_data under the model and return the posterior distribution (responsibilities) of each mixture component for each element of obs_data.
			Parameters:
				obs_data, must be a 2-d numpy.ndarray where every row is an event and every column a dimension
			Returns:
				log_prob, an array of log probabilities of each event in obs_data
				posteriors, posterior probabilities of each mixture component for each event in obs_data

		score( obs_data )
			Compute the log probability under the model
			Parameters:
				obs_data, must be a 2-d numpy.ndarray where every row is an event and every column a dimension
			Returns:
				log_prob, an array of log probabilities of each event in obs_data

		decode( obs_data )
			Find most likely mixture components for each point in obs_data
			Parameters:
				obs_data, must be a 2-d numpy.ndarray where every row is an event and every column a dimension
			Returns:
				log_prob, an array of log probabilities of each event in obs_data
				components, an array of indexes of the most likely mixture components for each event in obs_data

		predict( obs_data )
			Predict label for data
			Parameters:
				obs_data, must be a 2-d numpy.ndarray where every row is an event and every column a dimension
			Returns:
				components, an array of indexes of the most likely mixture components for each event in obs_data

		merge_components( c1, c2, new_component )
			Replace two components with a single new component
			Parameters:
				c1, the id of the first component to be merged
				c2, the id of the other component to be merged
				new_component, the new component
			
		compute_distance_rissanen( c1, c2 )
			Computes the distances between two components of the mixture
			Parameters:
				c1, the id of the first component to be compared
				c2, the id of the other component to be compared
			Returns:
				new_component, a new component object created by merging the two
				dist, the Rissanen distance score of the two components

compute_distance_BIC( gmm1, gmm2, data )
	Compute the distance between two Gaussian Mixture Models using the Bayesian Inference Criterion
	Parameters:
		gmm1, the first GMM
		gmm2, the other GMM
		data, a dataset which the score should be computed against
	Returns:
		temp_GMM, a new GMM created by merging and retraining the two GMMs
		score, the BIC score of the merged GMM

